#! /bin/bash
# Convenience script for users of Mount Sinai's demeter cluster.
# Executes the most recently modified guacamole jar with arguments for running on demeter.
#
# Example invocation:
#
# scripts/guacamole-demeter threshold \
# 	-reads hdfs://demeter-nn1/user/ahujaa01/ftp-trace.ncbi.nih.gov/1000genomes/ftp/data/HG00096/alignment/HG00096.mapped.ILLUMINA.bwa.GBR.low_coverage.20120522.bam \
#	 -out hdfs://demeter-nn1/user/odonnt02/threshold.gt.adam
#
set -e
set -x

export SPARK_JAVA_OPTS="-Dspark.default.parallelism=1024 -Dspark.shuffle.consolidateFiles=true -Xmx8g -Dspark.speculation=true"
jar=$(ls -tc guacamole-core/target/guacamole-?.*.jar | head -n 1)
jar_abs=$(pwd)/$jar

#Set SPARK_HOME
source /etc/spark/conf/spark-env.sh

# Grap Yarn dependencies and put them on the classpath
CLASSPATH=`$SPARK_HOME/bin/compute-classpath.sh`

SPARK_JAR=/opt/cloudera/parcels/CDH/lib/spark/assembly/lib/spark-assembly_2.10-0.9.0-cdh5.0.0-hadoop2.3.0-cdh5.0.0.jar
export SPARK_JAR
SPARK_YARN_APP_JAR=$jar_abs
export SPARK_YARN_APP_JAR

# What should we set this at?
SPARK_WORKER_INSTANCES=1000
export SPARK_WORKER_INSTANCES

# 8g is the maximum. Consider lowering this if your job is able to run with less.
SPARK_WORKER_MEMORY=7g
export SPARK_WORKER_MEMORY

exec time java -cp $CLASSPATH:$jar_abs -Xmx8g -XX:MaxPermSize=4g org.bdgenomics.guacamole.Guacamole \
    "$@" \
    -spark_master yarn-client \
    -spark_jar $jar_abs

